{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre trained network\n",
    "![imagen](https://www.researchgate.net/publication/336874848/figure/fig1/AS:819325225144320@1572353764073/Illustrations-of-transfer-learning-a-neural-network-is-pretrained-on-ImageNet-and.png)\n",
    "\n",
    "Estas son las arquitecturas de redes neuronales más utilizadas en la comunidad. Para más detalle sobre el funcionamiento de cada red, consultar el [Hands on Machine Learning for Python](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch14.html#cnn_chapter).\n",
    "* VGG-16\n",
    "* VGG-19\n",
    "* Inception V3\n",
    "* XCeption\n",
    "* ResNet-50\n",
    "\n",
    "Las redes se pueden incorporar entrenadas, o sin entrenar.\n",
    "\n",
    "## ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102875136/102869336 [==============================] - 370s 4us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50V2(input_shape=(224, 224, 3), include_top=True, weights='imagenet', classifier_activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "elu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n                                                                 conv4_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_2[0][0]            \n                                                                 conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n                                                                 conv5_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n                                                                 conv5_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n                                                                 conv5_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\npost_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n__________________________________________________________________________________________________\npost_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n__________________________________________________________________________________________________\navg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n__________________________________________________________________________________________________\npredictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n==================================================================================================\nTotal params: 25,613,800\nTrainable params: 25,568,360\nNon-trainable params: 45,440\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos algunas imagenes desde local, para ver qué tal funciona la red ResNet50V2 ya entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "img/bear-1.jpg\nimg/cat.8016.jpg\nimg/cat.8037.jpg\nimg/dog.11856.jpg\nimg/dog.11857.jpg\nimg/horse.jpg\nimg/karate.jpg\nimg/pizza.jpg\n(8, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    X = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        image = imread(path + '/' + file)\n",
    "        smallimage = cv2.resize(image, (224, 224))\n",
    "        print(path + '/' + file)\n",
    "        \n",
    "        X.append(smallimage)\n",
    "\n",
    "    return np.array(X)\n",
    "    \n",
    "\n",
    "x_test = read_data('img')\n",
    "\n",
    "# Procesar las imagenes tal y como entran en el modelo\n",
    "x_test = preprocess_input(x_test)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "40960/35363 [==================================] - 0s 3us/step\n",
      "###################\n",
      "Predicted:\n",
      " brown_bear 0.99944514\n",
      "Predicted:\n",
      " chow 0.0005413945\n",
      "Predicted:\n",
      " American_black_bear 8.784525e-06\n",
      "Predicted:\n",
      " ice_bear 1.1080914e-06\n",
      "Predicted:\n",
      " howler_monkey 4.4057413e-07\n",
      "###################\n",
      "Predicted:\n",
      " Egyptian_cat 0.6597232\n",
      "Predicted:\n",
      " Siamese_cat 0.15741065\n",
      "Predicted:\n",
      " tiger_cat 0.06259996\n",
      "Predicted:\n",
      " lynx 0.022836657\n",
      "Predicted:\n",
      " tabby 0.018356157\n",
      "###################\n",
      "Predicted:\n",
      " Egyptian_cat 0.82118624\n",
      "Predicted:\n",
      " lynx 0.1293217\n",
      "Predicted:\n",
      " Siamese_cat 0.021827262\n",
      "Predicted:\n",
      " tabby 0.018324584\n",
      "Predicted:\n",
      " tiger_cat 0.0067972722\n",
      "###################\n",
      "Predicted:\n",
      " Rottweiler 0.7618954\n",
      "Predicted:\n",
      " Brabancon_griffon 0.07461354\n",
      "Predicted:\n",
      " Staffordshire_bullterrier 0.028572643\n",
      "Predicted:\n",
      " EntleBucher 0.01990426\n",
      "Predicted:\n",
      " Doberman 0.019285155\n",
      "###################\n",
      "Predicted:\n",
      " collie 0.99525565\n",
      "Predicted:\n",
      " Shetland_sheepdog 0.004744308\n",
      "Predicted:\n",
      " yellow_lady's_slipper 9.7512345e-09\n",
      "Predicted:\n",
      " goldfinch 8.175388e-09\n",
      "Predicted:\n",
      " groenendael 7.4755615e-09\n",
      "###################\n",
      "Predicted:\n",
      " standard_poodle 0.32618576\n",
      "Predicted:\n",
      " Saluki 0.2963572\n",
      "Predicted:\n",
      " ram 0.12240917\n",
      "Predicted:\n",
      " bighorn 0.118147925\n",
      "Predicted:\n",
      " Ibizan_hound 0.060498767\n",
      "###################\n",
      "Predicted:\n",
      " ballplayer 0.5402335\n",
      "Predicted:\n",
      " baseball 0.2465795\n",
      "Predicted:\n",
      " balance_beam 0.11725283\n",
      "Predicted:\n",
      " torch 0.018078012\n",
      "Predicted:\n",
      " puck 0.009959695\n",
      "###################\n",
      "Predicted:\n",
      " pizza 0.9974214\n",
      "Predicted:\n",
      " bagel 0.0011646905\n",
      "Predicted:\n",
      " potpie 0.00081819936\n",
      "Predicted:\n",
      " carbonara 9.463589e-05\n",
      "Predicted:\n",
      " French_loaf 8.5963e-05\n"
     ]
    }
   ],
   "source": [
    "preds = base_model.predict(x_test)\n",
    "\n",
    "decodes = decode_predictions(preds, top=5)\n",
    "\n",
    "for j in decodes:\n",
    "    print('###################')\n",
    "\n",
    "    for i, decode in enumerate(j):\n",
    "        print('Predicted:\\n', decode[1], decode[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16\n",
    "En este caso vamos a importar la red VGG16, que utilizaremos como red preentrenada y completaremos con una fully connected layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IM_SIZE=64\n",
    "\n",
    "TRAIN_PATH = 'D:/ARTURO/BBDD/DATA ML-REDES-CONVOLUCIONALES/mini_train/train'\n",
    "filenames = os.listdir(TRAIN_PATH)\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    categories.append(category)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'filenames': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "train_df, validate_df = train_test_split(df,\n",
    "                                         test_size=0.20,\n",
    "                                         random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       filenames category\n",
       "0   cat.3337.jpg      cat\n",
       "1  dog.12039.jpg      dog\n",
       "2   cat.2542.jpg      cat\n",
       "3  dog.10283.jpg      dog\n",
       "4  dog.10384.jpg      dog"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filenames</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cat.3337.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dog.12039.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cat.2542.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dog.10283.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dog.10384.jpg</td>\n      <td>dog</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 5260 validated image filenames belonging to 2 classes.\nFound 1316 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col='filenames',\n",
    "                                                              y_col='category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 175s 3us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape=(IM_SIZE, IM_SIZE, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "##### FULLY CONNECTED LAYER #####\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "263/263 [==============================] - 79s 297ms/step - loss: 0.6529 - acc: 0.6619 - val_loss: 0.4846 - val_acc: 0.7652\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 81s 310ms/step - loss: 0.5414 - acc: 0.7297 - val_loss: 0.4524 - val_acc: 0.7796\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 86s 327ms/step - loss: 0.5179 - acc: 0.7436 - val_loss: 0.4565 - val_acc: 0.7789\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 86s 328ms/step - loss: 0.4996 - acc: 0.7616 - val_loss: 0.4460 - val_acc: 0.7895\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 86s 327ms/step - loss: 0.4870 - acc: 0.7655 - val_loss: 0.4366 - val_acc: 0.7910\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 88s 336ms/step - loss: 0.4888 - acc: 0.7577 - val_loss: 0.4416 - val_acc: 0.7918\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 87s 333ms/step - loss: 0.4863 - acc: 0.7668 - val_loss: 0.4321 - val_acc: 0.7994\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 90s 341ms/step - loss: 0.4912 - acc: 0.7654 - val_loss: 0.4317 - val_acc: 0.7994\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 89s 340ms/step - loss: 0.4754 - acc: 0.7589 - val_loss: 0.4528 - val_acc: 0.7888\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 91s 345ms/step - loss: 0.4725 - acc: 0.7683 - val_loss: 0.4304 - val_acc: 0.7888\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 5260 validated image filenames belonging to 2 classes.\nFound 1316 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IM_SIZE = 150\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col='filenames',\n",
    "                                                              y_col='category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 137s 2us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_model = InceptionV3(input_shape=(IM_SIZE, IM_SIZE, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 64s 584ms/step - loss: 13.0680 - acc: 0.7810 - val_loss: 1.0310 - val_acc: 0.9126\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 61s 611ms/step - loss: 0.7549 - acc: 0.8933 - val_loss: 0.1203 - val_acc: 0.9483\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 57s 574ms/step - loss: 0.2087 - acc: 0.9130 - val_loss: 0.1022 - val_acc: 0.9597\n"
     ]
    }
   ],
   "source": [
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "inc_history = model.fit(train_generator, validation_data=validation_generator, steps_per_epoch=100, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50V2 sin entrenar\n",
    "\n",
    "1. Importar solo capas convolucionales sin entrenar\n",
    "2. Desarrollar la fully connection layer\n",
    "3. Usar flow_from_dataframe\n",
    "4. Entrenar toda la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = 150\n",
    "\n",
    "base_model = ResNet50V2(input_shape=(IM_SIZE, IM_SIZE, 3), include_top=False, classifier_activation='softmax')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FULLY CONNECTED LAYER #####\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 5260 validated image filenames belonging to 2 classes.\nFound 1316 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col='filenames',\n",
    "                                                              y_col='category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 96s 919ms/step - loss: 4.3409 - acc: 0.8452 - val_loss: 2.0402 - val_acc: 0.9347\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 96s 963ms/step - loss: 2.9168 - acc: 0.9035 - val_loss: 0.6877 - val_acc: 0.9460\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 1.0134 - acc: 0.9058 - val_loss: 0.2895 - val_acc: 0.9271\n"
     ]
    }
   ],
   "source": [
    "inc_history = model.fit(train_generator, validation_data=validation_generator, steps_per_epoch=100, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0fc33febecb25bf51ecb9e8745ca02a2d49ab50b5c3e3d57ffb721b0f2206d5d8",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}